<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="Machine Learning, Android,Java,Python,C language,C#,C++,HTML,CSS,JavaScript,JQuery,Vue.js等"><meta name="description" content="成功的信念在人脑中的作用就如闹钟,会在你需要时将你唤醒"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>Machine Learning | Lj&#39;blog</title><link rel="icon" type="image/png" href="/liaojie.github.io/medias/dog.png"><link rel="stylesheet" type="text/css" href="/liaojie.github.io/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="/liaojie.github.io/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="/liaojie.github.io/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="/liaojie.github.io/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="/liaojie.github.io/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="/liaojie.github.io/css/matery.css"><link rel="stylesheet" type="text/css" href="/liaojie.github.io/css/my.css"><script src="/liaojie.github.io/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 5.4.0"><style>.github-emoji{position:relative;display:inline-block;width:1.2em;min-height:1.2em;overflow:hidden;vertical-align:top;color:transparent}.github-emoji>span{position:relative;z-index:10}.github-emoji .fancybox,.github-emoji img{margin:0!important;padding:0!important;border:none!important;outline:0!important;text-decoration:none!important;user-select:none!important;cursor:auto!important}.github-emoji img{height:1.2em!important;width:1.2em!important;position:absolute!important;left:50%!important;top:50%!important;transform:translate(-50%,-50%)!important;user-select:none!important;cursor:auto!important}.github-emoji-fallback{color:inherit}.github-emoji-fallback img{opacity:0!important}</style><link rel="alternate" href="/liaojie.github.io/atom.xml" title="Lj'blog" type="application/atom+xml"></head><script type="text/javascript">WIDGET={FID:"1tFpFZ5Mtj"}</script><script type="text/javascript">var windowWidth=$(window).width();768<windowWidth&&document.write('<script type="text/javascript" src="https://apip.weatherdt.com/float/static/js/r.js?v=1111"><\/script>')</script><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/liaojie.github.io/" class="waves-effect waves-light"><div><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/ljlogo.png" class="logo-img" alt="LOGO"> <span class="logo-span">Lj'blog</span></div></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/liaojie.github.io/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/liaojie.github.io/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/liaojie.github.io/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/liaojie.github.io/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>归档</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/liaojie.github.io/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/liaojie.github.io/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/liaojie.github.io/friends" class="waves-effect waves-light"><i class="fas fa-address-book" style="zoom:.6"></i> <span>友情链接</span></a></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/liaojie.github.io/medias/ljlogo.png" class="logo-img circle responsive-img"><div class="logo-name">Lj&#39;blog</div><div class="logo-desc">成功的信念在人脑中的作用就如闹钟,会在你需要时将你唤醒</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/liaojie.github.io/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/liaojie.github.io/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/liaojie.github.io/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/liaojie.github.io/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="/liaojie.github.io/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/liaojie.github.io/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="/liaojie.github.io/friends" class="waves-effect waves-light"><i class="fa-fw fas fa-address-book"></i> 友情链接</a></li></ul></div></div></nav></header><div class="bg-cover pd-header post-cover" style="background-image:url(/liaojie.github.io/medias/featureimages/1.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">Machine Learning</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="/liaojie.github.io/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{padding:35px 0 15px 17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{padding-bottom:30px;overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/liaojie.github.io/tags/Python/"><span class="chip bg-color">Python</span> </a><a href="/liaojie.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="chip bg-color">机器学习</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/liaojie.github.io/categories/Python/" class="post-category">Python</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2021-11-14</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2022-02-14</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 13.7k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 48 分</div><div id="busuanzi_container_page_pv" class="info-break-policy"><i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp; <span id="busuanzi_value_page_pv"></span></div></div></div><hr class="clearfix"><link rel="stylesheet" href="/liaojie.github.io/libs/prism/prism.css"><div class="card-content article-card-content"><div id="articleContent"><h1 id="机器学习概述"><a href="#机器学习概述" class="headerlink" title="机器学习概述"></a>机器学习概述</h1><h2 id="什么是机器学习"><a href="#什么是机器学习" class="headerlink" title="什么是机器学习"></a>什么是机器学习</h2><p>Arthur Samuel对机器学习的定义:</p><blockquote><p>在没有明确设置的情况下使计算机具有学习能力的研究领域<br>Tom Mitchell对机器学习的定义:<br>计算机程序从经验E中学习解决某一任务T进行某一性能度量P通过P测定在T上的表现因经验E而提高</p></blockquote><h2 id="为什么使用机器学习"><a href="#为什么使用机器学习" class="headerlink" title="为什么使用机器学习"></a>为什么使用机器学习</h2><ul><li><p>有解决方案(但解决方案需要进行大量人工微调或需要遵循大量规则)的问题:机器学习算法通常可以简化代码,相比传统方法有更好的性能。</p></li><li><p>传统方法难以解决的复杂问题:最好的机器学习技术也许可以找到解决方案。</p></li><li><p>环境有波动:机器学习算法可以适应新数据。</p></li><li><p>洞察复杂问题和大量数据。</p></li></ul><h2 id="机器学习系统的类型"><a href="#机器学习系统的类型" class="headerlink" title="机器学习系统的类型"></a>机器学习系统的类型</h2><ul><li><p>是否在人类监督下训练(有监督学习、无监督学习、半监督学习和强化学习)。</p></li><li><p>是否可以动态地进行增量学习(在线学习和批量学习)。</p></li><li><p>是简单地将新的数据点和已知的数据点进行匹配,还是像科学家那样,对训练数据进行模式检测然后建立一个预测模型(基于实例的学习和基于模型的学习)。</p></li></ul><h3 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h3><p>监督学习是指:利用一组已知类别的样本调整分类器的参数,使其达到所要求性能的过程,也称为监督训练或有教师学习。<br>监督学习是从标记的训练数据来推断一个功能的机器学习任务.训练数据包括一套训练示例.在监督学习中,每个实例都是由一个输入对象（通常为矢量）和一个期望的输出值（也称为监督信号）组成.监督学习算法是分析该训练数据,并产生一个推断的功能,其可以用于映射出新的实例.一个最佳的方案将允许该算法来正确地决定那些看不见的实例的类标签.这就要求学习算法是在一种”合理”的方式从一种从训练数据到看不见的情况下形成.</p><p>在有监督学习中,提供给算法的包含所需的解决方案的训练集称为标签。</p><p>分类任务是一个典型的有监督学习任务。另一个典型的任务是通过给定一组称为预测器的特征(里程、使用年限、品牌等)来预测一个目标数值(例如汽车的价格)。这种类型的任务称为回归。</p><blockquote><p>eg:判断良性和恶性肿瘤的概率</p></blockquote><p>最重要的有监督学习算法:</p><ul><li><p>k-近邻算法</p></li><li><p>线性回归</p></li><li><p>逻辑回归</p></li><li><p>支持向量机(SVM)</p></li><li><p>决策树和随机森林</p></li><li><p>神经网络</p></li></ul><h3 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h3><p>无监督学习的训练数据都是未经标记的。</p><p>无监督学习算法可能判定该数据集包含俩个不同的簇(聚类算法)</p><p><img src="/liaojie.github.io/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/liaojie1314/PicGo/images/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0.jpg" alt="无监督学习概述图"></p><p>现实生活中常常会有这样的问题:缺乏足够的先验知识,因此难以人工标注类别或进行人工类别标注的成本太高.很自然地,我们希望计算机能代我们完成这些工作,或至少提供一些帮助.根据类别未知(没有被标记)的训练样本解决模式识别中的各种问题,称之为无监督学习.</p><p>最重要的无监督学习算法:</p><ul><li><p>聚类算法</p><ul><li><p>k-均值算法</p></li><li><p>DBSCAN</p></li><li><p>分层聚类分析(HCA)</p></li></ul></li><li><p>异常检测和新颖性检测</p><ul><li><p>单类SVM</p></li><li><p>孤立森林</p></li></ul></li><li><p>可视化和降维</p><ul><li><p>主成分分析(PCA)</p></li><li><p>核主成分分析</p></li><li><p>局部线性嵌入(LLE)</p></li><li><p>t-分布随机近邻嵌入(t-SNE)</p></li></ul></li><li><p>关联规则学习</p><ul><li><p>Apriori</p></li><li><p>Eclat</p></li></ul></li></ul><h3 id="半监督学习"><a href="#半监督学习" class="headerlink" title="半监督学习"></a>半监督学习</h3><p>由于通常给数据做标记是非常耗时和昂贵的,你往往会有很多未标记的数据而很少有已标记的数据。有些算法可以处理部分已标记的数据。这被称为半监督学习。</p><p>大多数半监督学习算法是无监督算法和有监督算法的结合。例如,深度信念网络(DBN)基于一种互相堆叠的无监督组件,这个组件叫做受限玻尔兹曼机(RBM)。受限玻尔兹曼机以无监督方式进行训练,然后使用有监督学习技术对整个系统进行微调。</p><h3 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h3><p>强化学习的学习系统(在其语境中称为智能体)能够观察环境,做出选择,执行动作,并获得回报(或者是以负面回报的形式获得惩罚)。所以它必须自行学习什么是最好的策略,从而随着时间的推移获得最大的回报。策略代表智能体在特定情况下应该选择的动作。</p><h3 id="批量学习"><a href="#批量学习" class="headerlink" title="批量学习"></a>批量学习</h3><p>在批量学习中系统无法进行增量学习–即必须使用所有可用数据进行训练。这需要大量时间和计算资源,所以通常都是离线完成的。离线学习就是先训练系统,然后将其投入生产系统,这时学习过程停止,它只是将其所学到的应用出来。</p><p>如果希望批量学习系统学习新数据(例如新型垃圾邮件),需要在完整数据集(包括新数据和旧数据)的基础上重新训练系统的新版本,然后停用旧系统,用新系统取而代之。</p><p>幸运的是,整个训练、评估和启动机器学习系统的过程可以很轻松的实现自动化,所以即使是批量学习系统也能够适应变化。只是需要不断地更新数据,并根据需要频繁地训练系统的新版本。<br>这个解决方案比较简单,通常也都能正常工作,只是每次都使用完整数据集进行训练可能需要花上好几个小时,所以,你很有可能会选择每天甚至每周训练一次新系统。如果系统需要应对快速变化的数据(例如,预测股票价格),那么你需要一个更具响应力的解决方案。<br>此外,使用完整数据集训练需要耗费大量的计算资源(CPU、内存空间、磁盘空间、磁盘I/O、网络I/O等)。如果你的数据量非常大,并且每天从零开始自动执行训练系统,那最终你将为此花费大量的金钱。而假如你面对的是海量数据,甚至可能无法再应用批量学习算法。<br>所以如果你的资源有限(例如,一个智能手机应用程序或一个火星上的漫游器),而系统需要实现自主学习,那么像这样携带大量训练数据,占用大量资源,动辄每天耗费几小时来进行训练的方式,肯定会让你心有余而力不足。<br>幸运的是,在所有这些情况下,我们有一个更好的选择——能够进行增量学习的算法。</p><h3 id="在线学习"><a href="#在线学习" class="headerlink" title="在线学习"></a>在线学习</h3><p>在在线学习中,你可以循序渐进地给系统提供训练数据,逐步积累学习成果。这种提供进数据的方式可以是单独的,也可以采用小批量的小组数据来进行训练。每一步学习都很快速并且便宜,这样系统就可以根据飞速写入的最新数据进行学习。</p><p>对于需要接收持续的数据流的系统(例如股票价格),同时对数据流的变化做出快速或自主的反应,或者你的计算资源有限,又或者对于超大数据集,使用在线学习都是一个非常好的方式。</p><h3 id="基于实例的学习"><a href="#基于实例的学习" class="headerlink" title="基于实例的学习"></a>基于实例的学习</h3><p>系统用心学习示例,然后通过使用相似度度量来比较新实例和已经学习的实例(或他们的子集),从而泛化新实例。</p><h3 id="基于模型的学习"><a href="#基于模型的学习" class="headerlink" title="基于模型的学习"></a>基于模型的学习</h3><p>从一组示例集中实现泛化的另一种方法是构建这些示例,然后使用该模型进行预测。这称为基于模型的学习。</p><p>对于线性回归问题,通常的选择是使用成本函数来衡量线性模型的预测与训练实例之间的差距,目的在于尽量使这个差距最小化。</p><p>这正是线性回归算法的意义所在:通过你提供的训练样本,找出最符合提供数据的线性模型的参数,这称为训练模型。</p><h2 id="机器学习的主要挑战"><a href="#机器学习的主要挑战" class="headerlink" title="机器学习的主要挑战"></a>机器学习的主要挑战</h2><h3 id="训练数据的数量不足"><a href="#训练数据的数量不足" class="headerlink" title="训练数据的数量不足"></a>训练数据的数量不足</h3><h3 id="训练数据不具代表性"><a href="#训练数据不具代表性" class="headerlink" title="训练数据不具代表性"></a>训练数据不具代表性</h3><h3 id="低质量数据"><a href="#低质量数据" class="headerlink" title="低质量数据"></a>低质量数据</h3><h3 id="无关特征"><a href="#无关特征" class="headerlink" title="无关特征"></a>无关特征</h3><h3 id="过拟合训练数据"><a href="#过拟合训练数据" class="headerlink" title="过拟合训练数据"></a>过拟合训练数据</h3><p>可能的解决方法:</p><ul><li><p>简化模型:可以选择参数较少的模型(例如选择线性模型而不是高阶多项式模型)也可以减少训练数据中的属性数量,或者是约束模型。</p></li><li><p>收集更多的训练数据</p></li><li><p>减少训练数据中的噪音(例如,修复数据错误和消除异常项)</p></li></ul><p>通过约束模型使其更简单,并降低过拟合的风险,这个过程称为正则化。</p><p>正则化可降低过拟合风险。</p><h3 id="欠拟合训练数据"><a href="#欠拟合训练数据" class="headerlink" title="欠拟合训练数据"></a>欠拟合训练数据</h3><p>解决这个问题的主要方式有:</p><ul><li><p>选择一个带有更多参数、更强大的模型。</p></li><li><p>给学习算法提供更好的特征集(特征工程)。</p></li><li><p>减少模型中的约束(例如,减少正则化超参数)。</p></li></ul><h2 id="测试与验证"><a href="#测试与验证" class="headerlink" title="测试与验证"></a>测试与验证</h2><p>将数据分割为俩部分:训练集(一般80%)和测试集(一般20%)。</p><h3 id="超参数调整和模型选择"><a href="#超参数调整和模型选择" class="headerlink" title="超参数调整和模型选择"></a>超参数调整和模型选择</h3><h3 id="数据不匹配"><a href="#数据不匹配" class="headerlink" title="数据不匹配"></a>数据不匹配</h3><p>没有免费的午餐定理:如果你对数据绝对没有任何假设,那么就没有理由更偏好于某个模型。</p><h1 id="端到端的机器学习项目"><a href="#端到端的机器学习项目" class="headerlink" title="端到端的机器学习项目"></a>端到端的机器学习项目</h1><h2 id="使用真实数据"><a href="#使用真实数据" class="headerlink" title="使用真实数据"></a>使用真实数据</h2><p>获得数据的地方:</p><ul><li><p>流行的开放数据存储库</p><ul><li>UC Irvine Machine Learning Repository (<a target="_blank" rel="noopener" href="http://archive.ics.uci.edu/ml/">http://archive.ics.uci.edu/ml/</a>)</li><li>Kaggle datasets (<a target="_blank" rel="noopener" href="https://www.kaggle.com/datasets">https://www.kaggle.com/datasets</a>)</li><li>Amazon’s AWS datasets (<a target="_blank" rel="noopener" href="http://aws.amazon.com/fr/datasets/">http://aws.amazon.com/fr/datasets/</a>)</li></ul></li><li><p>元门户站点(它们会列出开放的数据存储库)</p><ul><li>Data Portals (<a target="_blank" rel="noopener" href="http://dataportals.org/">http://dataportals.org/</a>)</li><li>OpenDataMonitor (<a target="_blank" rel="noopener" href="http://opendatamonitor.eu/">http://opendatamonitor.eu/</a>)</li><li>Quandl (<a target="_blank" rel="noopener" href="http://quandl.com/">http://quandl.com/</a>)</li></ul></li><li><p>其他一些列出流行的开放数据存储库的页面:</p><ul><li>Wikipedia’s list of Machine Learning datasets (<a target="_blank" rel="noopener" href="https://goo.gl/SJHN2k">https://goo.gl/SJHN2k</a>)</li><li>Quora.com (<a target="_blank" rel="noopener" href="http://goo.gl/zDR78y">http://goo.gl/zDR78y</a>)</li><li>The datasets subreddit (<a target="_blank" rel="noopener" href="https://www.reddit.com/r/datasets">https://www.reddit.com/r/datasets</a>)</li></ul></li></ul><h3 id="观察大局"><a href="#观察大局" class="headerlink" title="观察大局"></a>观察大局</h3><h4 id="框架问题"><a href="#框架问题" class="headerlink" title="框架问题"></a>框架问题</h4><h4 id="选择性能指标"><a href="#选择性能指标" class="headerlink" title="选择性能指标"></a>选择性能指标</h4><p><img src="/liaojie.github.io/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/liaojie1314/PicGo/images/%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%871.jpg"></p><p><img src="/liaojie.github.io/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/liaojie1314/PicGo/images/%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%872.jpg"></p><p><img src="/liaojie.github.io/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/liaojie1314/PicGo/images/%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%873.jpg"></p><h4 id="检查假设"><a href="#检查假设" class="headerlink" title="检查假设"></a>检查假设</h4><h3 id="获取数据"><a href="#获取数据" class="headerlink" title="获取数据"></a>获取数据</h3><hr><h2 id="机器学习概述-1"><a href="#机器学习概述-1" class="headerlink" title="机器学习概述"></a>机器学习概述</h2><h3 id="人工智能应用场景"><a href="#人工智能应用场景" class="headerlink" title="人工智能应用场景"></a>人工智能应用场景</h3><p><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF.png"></p><h3 id="人工智能小案例"><a href="#人工智能小案例" class="headerlink" title="人工智能小案例"></a>人工智能小案例</h3><ol><li>你画我猜</li></ol><p>参考链接：<a target="_blank" rel="noopener" href="https://quickdraw.withgoogle.com/">https://quickdraw.withgoogle.com</a></p><ol start="2"><li>识别</li></ol><p>参考链接：<a target="_blank" rel="noopener" href="https://pjreddie.com/darknet/yolo/">https://pjreddie.com/darknet/yolo/</a></p><ol start="3"><li>风格迁移</li></ol><p>查看更多：<a target="_blank" rel="noopener" href="https://deepdreamgenerator.com/">https://deepdreamgenerator.com/</a></p><h3 id="人工智能发展必备三要素："><a href="#人工智能发展必备三要素：" class="headerlink" title="人工智能发展必备三要素："></a>人工智能发展必备三要素：</h3><ul><li>数据</li><li>算法</li><li>计算力<ul><li>CPU,GPU,TPU</li></ul></li></ul><p>计算力之CPU、GPU对比：</p><ul><li>CPU主要适合I\O密集型的任务</li><li>GPU主要适合计算密集型任务</li></ul><p>提问：什么类型的程序适合在GPU上运行？</p><p>（1）计算密集型的程序。<br>所谓计算密集型(Compute-intensive)的程序，就是其大部分运行时间花在了寄存器运算上，寄存器的速度和处理器的速度相当，从寄存器读写<br>数据几乎没有延时。可以做一下对比，读内存的延迟大概是几百个时钟周期；读硬盘的速度就不说了，即便是SSD, 也实在是太慢了。<br>（2）易于并行的程序。<br>GPU其实是一种SIMD(Single Instruction Multiple Data)架构， 他有成百上千个核，每一个核在同一时间最好能做同样的事情。</p><p>CPU和GPU的区别：<br><a target="_blank" rel="noopener" href="http://www.sohu.com/a/201309334_468740">http://www.sohu.com/a/201309334_468740</a></p><p>Google TPU 介绍：<br><a target="_blank" rel="noopener" href="https://buzzorange.com/techorange/2017/09/27/what-intel-google-nvidia-microsoft-do-for-ai-chips/">https://buzzorange.com/techorange/2017/09/27/what-intel-google-nvidia-microsoft-do-for-ai-chips/</a></p><h3 id="人工智能、机器学习和深度学习"><a href="#人工智能、机器学习和深度学习" class="headerlink" title="人工智能、机器学习和深度学习"></a>人工智能、机器学习和深度学习</h3><p><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.png"></p><p>人工智能和机器学习，深度学习的关系</p><ul><li>机器学习是人工智能的一个实现途径</li><li>深度学习是机器学习的一个方法发展而来</li></ul><h2 id="人工智能发展历程"><a href="#人工智能发展历程" class="headerlink" title="人工智能发展历程"></a>人工智能发展历程</h2><h3 id="人工智能的起源"><a href="#人工智能的起源" class="headerlink" title="人工智能的起源"></a>人工智能的起源</h3><h4 id="1-1-图灵测试"><a href="#1-1-图灵测试" class="headerlink" title="1.1 图灵测试"></a>1.1 图灵测试</h4><p>测试者与被测试者（一个人和一台机器）隔开的情况下，通过一些装置（如键盘）向被测试者随意提问。<br>多次测试（一般为5min之内），如果有超过30%的测试者不能确定被测试者是人还是机器，那么这台机器就通过了测试，并被认为具有人类智能。</p><h4 id="1-2-达特茅斯会议"><a href="#1-2-达特茅斯会议" class="headerlink" title="1.2 达特茅斯会议"></a>1.2 达特茅斯会议</h4><p>1956年8月，在美国汉诺斯小镇宁静的达特茅斯学院中，<br>约翰·麦卡锡（John McCarthy）<br>马文·闵斯基（Marvin Minsky，人工智能与认知学专家）<br>克劳德·香农（Claude Shannon，信息论的创始人）<br>艾伦·纽厄尔（Allen Newell，计算机科学家）<br>赫伯特·西蒙（Herbert Simon，诺贝尔经济学奖得主）等科学家正聚在一起，讨论着一个完全不食人间烟火的主题：<br>用机器来模仿人类学习以及其他方面的智能。<br>会议足足开了两个月的时间，虽然大家没有达成普遍的共识，但是却为会议讨论的内容起了一个名字：<br>人工智能<br>因此，1956年也就成为了人工智能元年。</p><h3 id="发展历程"><a href="#发展历程" class="headerlink" title="发展历程"></a>发展历程</h3><p>人工智能充满未知的探索道路曲折起伏。如何描述人工智能自1956年以来60余年的发展历程，学术界可谓仁者见仁、智者见智。我们将人工智<br>能的发展历程划分为以下6个阶段：</p><ul><li><p>第一是起步发展期：1956年—20世纪60年代初。<br>人工智能概念提出后，相继取得了一批令人瞩目的研究成果，如机器定理证明、跳棋程序等，掀起人工智能发展的第一个高潮。</p></li><li><p>第二是反思发展期：20世纪60年代—70年代初。<br>人工智能发展初期的突破性进展大大提升了人们对人工智能的期望，人们开始尝试更具挑战性的任务，并提出了一些不切实际的研发目标。然而，接二连三的失败和预期目标的落空（例如，无法用机器证明两个连续函数之和还是连续函数、机器翻译闹出笑话等），使人工智能的发展走入低谷。</p></li><li><p>第三是应用发展期：20世纪70年代初—80年代中。<br>20世纪70年代出现的专家系统模拟人类专家的知识和经验解决特定领域的问题，实现了人工智能从理论研究走向实际应用、从一般推理策略探讨转向运用专门知识的重大突破。专家系统在医疗、化学、地质等领域取得成功，推动人工智能走入应用发展的新高潮。</p></li><li><p>第四是低迷发展期：20世纪80年代中—90年代中。<br>随着人工智能的应用规模不断扩大，专家系统存在的应用领域狭窄、缺乏常识性知识、知识获取困难、推理方法单一、缺乏分布式功能、难以与现有数据库兼容等问题逐渐暴露出来。</p></li><li><p>第五是稳步发展期：20世纪90年代中—2010年。<br>由于网络技术特别是互联网技术的发展，加速了人工智能的创新研究，促使人工智能技术进一步走向实用化。1997年国际商业机器公司（简称IBM）深蓝超级计算机战胜了国际象棋世界冠军卡斯帕罗夫，2008年IBM提出“智慧地球”的概念。以上都是这一时期的标志性事件。</p></li><li><p>第六是蓬勃发展期：2011年至今。<br>随着大数据、云计算、互联网、物联网等信息技术的发展，泛在感知数据和图形处理器等计算平台推动以深度神经网络为代表的人工智能技术飞速发展，大幅跨越了科学与应用之间的“技术鸿沟”，诸如图像分类、语音识别、知识问答、人机对弈、无人驾驶等人工智能技术实现了从“不能用、不好用”到“可以用”的技术突破，迎来爆发式增长的新高潮。</p></li></ul><p><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B.png"></p><h2 id="人工智能主要分支"><a href="#人工智能主要分支" class="headerlink" title="人工智能主要分支"></a>人工智能主要分支</h2><h3 id="主要分支介绍"><a href="#主要分支介绍" class="headerlink" title="主要分支介绍"></a>主要分支介绍</h3><p>通讯、感知与行动是现代人工智能的三个关键能力，在这里我们将根据这些能力/应用对这三个技术领域进行介绍：</p><ul><li>计算机视觉(CV)、</li><li>自然语言处理(NLP)<ul><li>在 NLP 领域中，将覆盖文本挖掘/分类、机器翻译和语音识别。</li></ul></li><li>机器人</li></ul><h4 id="1-1-分支一：计算机视觉"><a href="#1-1-分支一：计算机视觉" class="headerlink" title="1.1 分支一：计算机视觉"></a>1.1 分支一：计算机视觉</h4><p>计算机视觉(CV)是指机器感知环境的能力。这一技术类别中的经典任务有图像形成、图像处理、图像提取和图像的三维推理。物体检测和人脸识别是其比较成功的研究领域。</p><p>当前阶段：</p><p>计算机视觉现已有很多应用，这表明了这类技术的成就，也让我们将其归入到应用阶段。随着深度学习的发展，机器甚至能在特定的案例中实现超越人类的表现。但是，这项技术离社会影响阶段还有一定距离，那要等到机器能在所有场景中都达到人类的同等水平才行(感知其环境的所有相关方面)。</p><p>发展历史：</p><p><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2.png"></p><h4 id="1-2-分支二：语音识别"><a href="#1-2-分支二：语音识别" class="headerlink" title="1.2 分支二：语音识别"></a>1.2 分支二：语音识别</h4><p>语音识别是指识别语音(说出的语言)并将其转换成对应文本的技术。相反的任务(文本转语音/TTS)也是这一领域内一个类似的研究主题。</p><p>当前阶段：</p><p>语音识别已经处于应用阶段很长时间了。最近几年，随着大数据和深度学习技术的发展，语音识别进展颇丰，现在已经非常接近社会影响阶段了。<br>语音识别领域仍然面临着声纹识别和「鸡尾酒会效应」等一些特殊情况的难题。<br>现代语音识别系统严重依赖于云，在离线时可能就无法取得理想的工作效果。</p><p>发展历史：</p><p><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B21.png"><br><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B22.png"></p><h4 id="1-3-分支三：文本挖掘-分类"><a href="#1-3-分支三：文本挖掘-分类" class="headerlink" title="1.3 分支三：文本挖掘/分类"></a>1.3 分支三：文本挖掘/分类</h4><p>这里的文本挖掘主要是指文本分类，该技术可用于理解、组织和分类结构化或非结构化文本文档。其涵盖的主要任务有句法分析、情绪分析和垃圾信息检测。</p><p>当前阶段：</p><p>我们将这项技术归类到应用阶段，因为现在有很多应用都已经集成了基于文本挖掘的情绪分析或垃圾信息检测技术。文本挖掘技术也在智能投顾的开发中有所应用，并且提升了用户体验。<br>文本挖掘和分类领域的一个瓶颈出现在歧义和有偏差的数据上。</p><p>发展历史：</p><p><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2.png"></p><h4 id="1-4-分支四：机器翻译"><a href="#1-4-分支四：机器翻译" class="headerlink" title="1.4 分支四：机器翻译"></a>1.4 分支四：机器翻译</h4><p>机器翻译(MT)是利用机器的力量自动将一种自然语言(源语言)的文本翻译成另一种语言(目标语言)。</p><p>当前阶段：</p><p>机器翻译是一个见证了大量发展历程的应用领域。该领域最近由于神经机器翻译而取得了非常显著的进展，但仍然没有全面达到专业译者的水平；但是，我们相信在大数据、云计算和深度学习技术的帮助下，机器翻译很快就将进入社会影响阶段。<br>在某些情况下，俚语和行话等内容的翻译会比较困难(受限词表问题)。<br>专业领域的机器翻译(比如医疗领域)表现通常不好。</p><p>发展历史：</p><p><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2.png"></p><h4 id="1-5-分支五：机器人"><a href="#1-5-分支五：机器人" class="headerlink" title="1.5 分支五：机器人"></a>1.5 分支五：机器人</h4><p>机器人学(Robotics)研究的是机器人的设计、制造、运作和应用，以及控制它们的计算机系统、传感反馈和信息处理。</p><p>机器人可以分成两大类:固定机器人和移动机器人。固定机器人通常被用于工业生产(比如用于装配线)。常见的移动机器人应用有货运机器人、空中机器人和自动载具。机器人需要不同部件和系统的协作才能实现最优的作业。其中在硬件上包含传感器、反应器和控制器；另外还有能够实现感知能力的软件，比如定位、地图测绘和目标识别。</p><p>当前阶段：</p><p>自上世纪「Robot」一词诞生以来，人们已经为工业制造业设计了很多机器人。工业机器人是增长最快的应用领域，它们在 20 世纪 80 年代将这一领域带入了应用阶段。在安川电机、Fanuc、ABB、库卡等公司的努力下，我们认为进入 21 世纪之后，机器人领域就已经进入了社会影响阶段，此时各种工业机器人已经主宰了装配生产线。此外，软体机器人在很多领域也有广泛的应用，比如在医疗行业协助手术或在金融行业自动执行承销过程。但是，法律法规和「机器人威胁论」可能会妨碍机器人领域的发展。还有设计和制造机器人需要相对较高的投资。</p><p>发展历史：</p><p><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2.png"></p><p>总的来说，人工智能领域的研究前沿正逐渐从搜索、知识和推理领域转向机器学习、深度学习、计算机视觉和机器人领域。</p><p>大多数早期技术至少已经处于应用阶段了，而且其中一些已经显现出了社会影响力。一些新开发的技术可能仍处于工程甚至研究阶段，但是我们可以看到不同阶段之间转移的速度变得越来越快。</p><h2 id="机器学习工作流程"><a href="#机器学习工作流程" class="headerlink" title="机器学习工作流程"></a>机器学习工作流程</h2><h3 id="什么是机器学习-1"><a href="#什么是机器学习-1" class="headerlink" title="什么是机器学习"></a>什么是机器学习</h3><p>机器学习是从数据中自动分析获得模型，并利用模型对未知数据进行预测。</p><p><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.png"></p><h3 id="机器学习工作流程-1"><a href="#机器学习工作流程-1" class="headerlink" title="机器学习工作流程"></a>机器学习工作流程</h3><p><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png"></p><p>机器学习工作流程总结<br>1.获取数据<br>2.数据基本处理<br>3.特征工程<br>4.机器学习(模型训练)<br>5.模型评估</p><ul><li>结果达到要求，上线服务</li><li>没有达到要求，重新上面步骤</li></ul><h4 id="2-1-获取到的数据集介绍"><a href="#2-1-获取到的数据集介绍" class="headerlink" title="2.1 获取到的数据集介绍"></a>2.1 获取到的数据集介绍</h4><p>数据简介</p><p>在数据集中一般：</p><ul><li>一行数据我们称为一个样本</li><li>一列数据我们成为一个特征</li><li>有些数据有目标值（标签值），有些数据没有目标值（如上表中，电影类型就是这个数据集的目标值）</li></ul><p>数据类型构成：</p><ul><li>数据类型一：特征值+目标值（目标值是连续的和离散的）</li><li>数据类型二：只有特征值，没有目标值</li></ul><p>数据分割：</p><ul><li><p>机器学习一般的数据集会划分为两个部分：</p><ul><li>训练数据：用于训练，构建模型</li><li>测试数据：在模型检验时使用，用于评估模型是否有效</li></ul></li><li><p>划分比例：</p><ul><li>训练集：70% 80% 75%</li><li>测试集：30% 20% 25%</li></ul></li></ul><h4 id="2-2-数据基本处理"><a href="#2-2-数据基本处理" class="headerlink" title="2.2 数据基本处理"></a>2.2 数据基本处理</h4><p>即对数据进行缺失值、去除异常值等处理</p><h4 id="2-3-特征工程"><a href="#2-3-特征工程" class="headerlink" title="2.3 特征工程"></a>2.3 特征工程</h4><p>2.3.1什么是特征工程</p><p>特征工程是使用专业背景知识和技巧处理数据，使得特征能在机器学习算法上发挥更好的作用的过程。</p><p>意义：会直接影响机器学习的效果</p><p>2.3.2 为什么需要特征工程(Feature Engineering)</p><blockquote><p>机器学习领域的大神Andrew Ng(吴恩达)老师说“Coming up with features is difficult, time-consuming, requires expert knowledge.“Applied machine learning” is basically feature engineering. ”<br>注：业界广泛流传：数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。</p></blockquote><p>2.3.3 特征工程包含内容</p><ul><li>特征提取</li><li>特征预处理</li><li>特征降维</li></ul><p>2.3.4 各概念具体解释</p><ul><li>特征提取<ul><li>将任意数据（如文本或图像）转换为可用于机器学习的数字特征</li></ul></li><li>特征预处理<ul><li>通过一些转换函数将特征数据转换成更加适合算法模型的特征数据过程<br><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/%E7%89%B9%E5%BE%81%E9%A2%84%E5%A4%84%E7%90%86.png"></li></ul></li><li>特征降维<ul><li>指在某些限定条件下，降低随机变量(特征)个数，得到一组“不相关”主变量的过程</li></ul></li></ul><h4 id="2-4-机器学习"><a href="#2-4-机器学习" class="headerlink" title="2.4 机器学习"></a>2.4 机器学习</h4><p>选择合适的算法对模型进行训练（具体内容见1.5）</p><h4 id="2-5-模型评估"><a href="#2-5-模型评估" class="headerlink" title="2.5 模型评估"></a>2.5 模型评估</h4><p>对训练好的模型进行评估（具体内容见1.6）</p><p>拓展阅读：<br>完整机器学习项目的流程</p><h2 id="机器学习算法分类"><a href="#机器学习算法分类" class="headerlink" title="机器学习算法分类"></a>机器学习算法分类</h2><h3 id="监督学习-1"><a href="#监督学习-1" class="headerlink" title="监督学习"></a>监督学习</h3><p>定义：</p><ul><li>输入数据是由输入特征值和目标值所组成。<ul><li>函数的输出可以是一个连续的值(称为回归），</li><li>或是输出是有限个离散值（称作分类）。</li></ul></li></ul><h4 id="1-1-回归问题"><a href="#1-1-回归问题" class="headerlink" title="1.1 回归问题"></a>1.1 回归问题</h4><p>例如：预测房价，根据样本集拟合出一条连续曲线。</p><p><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/%E9%A2%84%E6%B5%8B%E6%88%BF%E4%BB%B7.png"></p><h4 id="1-2-分类问题"><a href="#1-2-分类问题" class="headerlink" title="1.2 分类问题"></a>1.2 分类问题</h4><p>例如：根据肿瘤特征判断良性还是恶性，得到的是结果是“良性”或者“恶性”，是离散的。</p><p><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/%E5%88%A4%E6%96%AD%E8%82%BF%E7%98%A4.png"></p><h3 id="无监督学习-1"><a href="#无监督学习-1" class="headerlink" title="无监督学习"></a>无监督学习</h3><p>定义：</p><ul><li>输入数据是由输入特征值组成，没有目标值<ul><li>输入数据没有被标记，也没有确定的结果。样本数据类别未知；</li><li>需要根据样本间的相似性对样本集进行类别划分。</li></ul></li></ul><p>有监督，无监督算法对比：</p><p><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/%E6%9C%89%E6%97%A0%E7%9B%91%E7%9D%A3%E7%AE%97%E6%B3%95%E5%AF%B9%E6%AF%94.png"></p><h3 id="半监督学习-1"><a href="#半监督学习-1" class="headerlink" title="半监督学习"></a>半监督学习</h3><p>定义：</p><ul><li>训练集同时包含有标记样本数据和未标记样本数据。</li></ul><p>举例：<br>监督学习训练方式：</p><p><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83%E6%96%B9%E5%BC%8F.png"></p><p>半监督学习训练方式</p><p><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83%E6%96%B9%E5%BC%8F.png"></p><h3 id="强化学习-1"><a href="#强化学习-1" class="headerlink" title="强化学习"></a>强化学习</h3><p>定义：</p><ul><li>实质是make decisions 问题，即自动进行决策，并且可以做连续决策。</li></ul><p>举例：</p><p>小孩想要走路，但在这之前，他需要先站起来，站起来之后还要保持平衡，接下来还要先迈出一条腿，是左腿还是右腿，迈出一步后还要迈出下一步。</p><p>小孩就是 agent，他试图通过采取行动（即行走）来操纵环境（行走的表面），并且从一个状态转变到另一个状态（即他走的每一步），当他完成任务的子任务（即走了几步）时，孩子得到奖励（给巧克力吃），并且当他不能走路时，就不会给巧克力。</p><p>主要包含五个元素：agent, action, reward, environment, observation；</p><p><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/agentactionrewardenvironmentobservation.png"></p><p>强化学习的目标就是获得最多的累计奖励。</p><p>监督学习和强化学习的对比</p><table><thead><tr><th></th><th>监督学习</th><th>强化学习</th></tr></thead><tbody><tr><td>反馈映射</td><td>输出的是之间的关系，可以告诉算法什么样的输入对应着什么样的输出。</td><td>输出的是给机器的反馈 reward function，即用来判断这个行为是好是坏。</td></tr><tr><td>反馈时间</td><td>做了比较坏的选择会立刻反馈给算法。</td><td>结果反馈有延时，有时候可能需要走了很多步以后才知道以前的某一步的选择是好还是坏。</td></tr><tr><td>输入特征</td><td>输入是独立同分布的。</td><td>面对的输入总是在变化，每当算法做出一个行为，它影响下一次决策的输入。</td></tr></tbody></table><p>拓展概念：什么是独立同分布：</p><p>独立同分布概念</p><p>拓展阅读：Alphago进化史 漫画告诉你Zero为什么这么牛：</p><p><a target="_blank" rel="noopener" href="http://sports.sina.com.cn/chess/weiqi/2017-10-21/doc-ifymyyxw4023875.shtm">http://sports.sina.com.cn/chess/weiqi/2017-10-21/doc-ifymyyxw4023875.shtm</a></p><h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><p>模型评估是模型开发过程不可或缺的一部分。它有助于发现表达数据的最佳模型和所选模型将来工作的性能如何。<br>按照数据集的目标值不同，可以把模型评估分为分类模型评估和回归模型评估。</p><h3 id="分类模型评估"><a href="#分类模型评估" class="headerlink" title="分类模型评估"></a>分类模型评估</h3><p>准确率</p><ul><li>预测正确的数占样本总数的比例。</li></ul><p>其他评价指标：精确率、召回率、F1-score、AUC指标等</p><h2 id="回归模型评估"><a href="#回归模型评估" class="headerlink" title="回归模型评估"></a>回归模型评估</h2><p>均方根误差（Root Mean Squared Error，RMSE）</p><ul><li>RMSE是一个衡量回归模型误差率的常用公式。 不过，它仅能比较误差是相同单位的模型</li></ul><p><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/RMSE.png"></p><h2 id="拟合"><a href="#拟合" class="headerlink" title="拟合"></a>拟合</h2><p>模型评估用于评价训练好的的模型的表现效果，其表现效果大致可以分为两类：过拟合、欠拟合。</p><p>在训练过程中，你可能会遇到如下问题：<br>训练数据训练的很好啊，误差也不大，为什么在测试集上面有问题呢？<br>当算法在某个数据集当中出现这种情况，可能就出现了拟合问题。</p><h3 id="3-1-欠拟合"><a href="#3-1-欠拟合" class="headerlink" title="3.1 欠拟合"></a>3.1 欠拟合</h3><p><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/%E6%AC%A0%E6%8B%9F%E5%90%88.png"></p><p>因为机器学习到的天鹅特征太少了，导致区分标准太粗糙，不能准确识别出天鹅。</p><p>欠拟合（under-fitting）：模型学习的太过粗糙，连训练集中的样本数据特征关系都没有学出来。</p><h3 id="3-2-过拟合"><a href="#3-2-过拟合" class="headerlink" title="3.2 过拟合"></a>3.2 过拟合</h3><p><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/%E8%BF%87%E6%8B%9F%E5%90%88.png"></p><p>机器已经基本能区别天鹅和其他动物了。然后，很不巧已有的天鹅图片全是白天鹅的，于是机器经过学习后，会认为天鹅的羽毛都是白的，以后看到羽毛是黑的天鹅就会认为那不是天鹅。</p><p>过拟合（over-fitting）：所建的机器学习模型或者是深度学习模型在训练样本中表现得过于优越，导致在测试数据集中表现不佳。</p><p>上问题解答：</p><p>训练数据训练的很好啊，误差也不大，为什么在测试集上面有问题呢？</p><h2 id="Azure机器学习模型搭建实验"><a href="#Azure机器学习模型搭建实验" class="headerlink" title="Azure机器学习模型搭建实验"></a>Azure机器学习模型搭建实验</h2><p>Azure平台简介</p><p><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/Azure%E5%B9%B3%E5%8F%B0%E7%AE%80%E4%BB%8B.png"></p><p>Azure Machine Learning（简称“AML”）是微软在其公有云Azure上推出的基于Web使用的一项机器学习服务，机器学习属人工智能的一个分支，它技术借助算法让电脑对大量流动数据集进行识别。这种方式能够通过历史数据来预测未来事件和行为，其实现方式明显优于传统的商业智能形式。</p><p>微软的目标是简化使用机器学习的过程，以便于开发人员、业务分析师和数据科学家进行广泛、便捷地应用。<br>这款服务的目的在于“将机器学习动力与云计算的简单性相结合”。<br>AML目前在微软的Global Azure云服务平台提供服务，用户可以通过站点：<a target="_blank" rel="noopener" href="https://studio.azureml.net/">https://studio.azureml.net/</a> 申请免费试用。</p><p><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B7%A5%E4%BD%9C%E5%AE%A4.png"></p><p>Azure机器学习实验</p><p>实验目的：了解机器学习从数据到建模并最终评估预测的整个流程。</p><p><a target="_blank" rel="noopener" href="https://github.com/liaojie1314/Azure">Azure机器学习实验操作文档</a></p><h2 id="深度学习简介"><a href="#深度学习简介" class="headerlink" title="深度学习简介"></a>深度学习简介</h2><h3 id="深度学习-——-神经网络简介"><a href="#深度学习-——-神经网络简介" class="headerlink" title="深度学习 —— 神经网络简介"></a>深度学习 —— 神经网络简介</h3><p>深度学习（Deep Learning）（也称为深度结构学习【Deep Structured Learning】、层次学习【Hierarchical Learning】或者是深度机器学习</p><p>【Deep Machine Learning】）是一类算法集合，是机器学习的一个分支。</p><p>深度学习方法近年来，在会话识别、图像识别和对象侦测等领域表现出了惊人的准确性。<br>但是，“深度学习”这个词语很古老，它在1986年由Dechter在机器学习领域提出，然后在2000年有Aizenberg等人引入到人工神经网络中。而现在，由于Alex Krizhevsky在2012年使用卷积网络结构赢得了ImageNet比赛之后受到大家的瞩目。</p><p>卷积网络之父：Yann LeCun</p><p>深度学习演示</p><p>链接:<a target="_blank" rel="noopener" href="http://playground.tensorflow.org/">http://playground.tensorflow.org</a></p><h3 id="深度学习各层负责内容"><a href="#深度学习各层负责内容" class="headerlink" title="深度学习各层负责内容"></a>深度学习各层负责内容</h3><p>神经网络各层负责内容：</p><p>1层：负责识别颜色及简单纹理</p><p>2层：一些神经元可以识别更加细化的纹理，布纹，刻纹，叶纹等</p><p>3层：一些神经元负责感受黑夜里的黄色烛光，高光，萤火，鸡蛋黄色等</p><p>4层：一些神经元识别萌狗的脸，宠物形貌，圆柱体事物，七星瓢虫等的存在。</p><p>5层：一些神经元负责识别花，黑眼圈动物，鸟，键盘，原型屋顶等。</p><h1 id="机器学习基础环境安装与使用"><a href="#机器学习基础环境安装与使用" class="headerlink" title="机器学习基础环境安装与使用"></a>机器学习基础环境安装与使用</h1><h2 id="库的安装"><a href="#库的安装" class="headerlink" title="库的安装"></a>库的安装</h2><p>整个机器学习基础阶段会用到Matplotlib、Numpy、Pandas等库，为了统一版本号在环境中使用，将所有的库及其版本放到了文件requirements.txt当中，然后统一安装</p><p>新建一个用于人工智能环境的虚拟环境</p><blockquote><p>mkvirtualenv ai</p></blockquote><pre class="line-numbers language-none"><code class="language-none">matplotlib==2.2.2
numpy==1.14.2
pandas==0.20.3
tables==3.4.2
jupyter==1.0.0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注意：<br>每个包安装的过程中，尽量指定稳定版本进行安装</p><p>使用pip命令安装</p><blockquote><p>pip3 install -r requirements.txt</p></blockquote><h2 id="Jupyter-Notebook使用"><a href="#Jupyter-Notebook使用" class="headerlink" title="Jupyter Notebook使用"></a>Jupyter Notebook使用</h2><h3 id="Jupyter-Notebook介绍"><a href="#Jupyter-Notebook介绍" class="headerlink" title="Jupyter Notebook介绍"></a>Jupyter Notebook介绍</h3><p>Jupyter项目是一个非盈利的开源项目，源于2014年的ipython项目，因为它逐渐发展为支持跨所有编程语言的交互式数据科学和科学计算</p><ul><li>Jupyter Notebook，原名IPython Notbook，是IPython的加强网页版，一个开源Web应用程序</li><li>名字源自Julia、Python 和 R（数据科学的三种开源语言）</li><li>是一款程序员和科学工作者的编程/文档/笔记/展示软件</li><li>.ipynb文件格式是用于计算型叙述的JSON文档格式的正式规范</li></ul><h3 id="为什么使用Jupyter-Notebook"><a href="#为什么使用Jupyter-Notebook" class="headerlink" title="为什么使用Jupyter Notebook?"></a>为什么使用Jupyter Notebook?</h3><p>传统软件开发：工程／目标明确</p><ul><li>需求分析，设计架构，开发模块，测试<br>数据挖掘：艺术／目标不明确</li><li>目的是具体的洞察目标，而不是机械的完成任务</li><li>通过执行代码来理解问题</li><li>迭代式地改进代码来改进解决方法</li></ul><p>实时运行的代码、叙事性的文本和可视化被整合在一起，方便使用代码和数据来讲述故事</p><p>对比Jupyter Notebook和Pycharm</p><ul><li>画图</li><li>数据展示</li></ul><p>总结：Jupyter Notebook 相比 Pycharm 在画图和数据展示方面更有优势。</p><h3 id="Jupyter-Notebook的使用-helloworld"><a href="#Jupyter-Notebook的使用-helloworld" class="headerlink" title="Jupyter Notebook的使用-helloworld"></a>Jupyter Notebook的使用-helloworld</h3><h4 id="3-1-界面启动、创建文件"><a href="#3-1-界面启动、创建文件" class="headerlink" title="3.1 界面启动、创建文件"></a>3.1 界面启动、创建文件</h4><p>3.1.1 界面启动</p><p>环境搭建好后，本机输入jupyter notebook命令，会自动弹出浏览器窗口打开Jupyter Notebook</p><pre class="line-numbers language-none"><code class="language-none"># 进入虚拟环境
workon ai
# 输入命令
jupyter notebook<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>本地notebook的默认URL为：<a target="_blank" rel="noopener" href="http://localhost:8888/">http://localhost:8888</a><br>想让notebook打开指定目录，只要进入此目录后执行命令即可</p><p>3.1.2 新建notebook文档</p><ul><li>notebook的文档格式是 <code>.ipynb</code></li></ul><p>3.1.3 内容界面操作</p><p>标题栏：点击标题（如Untitled）修改文档名<br>编辑栏：</p><h4 id="3-2-cell操作"><a href="#3-2-cell操作" class="headerlink" title="3.2 cell操作"></a>3.2 cell操作</h4><p>什么是cell？</p><ul><li>cell：一对In Out会话被视作一个代码单元，称为cell</li><li>cell行号前的 * ，表示代码正在运行</li></ul><p>Jupyter支持两种模式：</p><p>编辑模式（Enter）</p><ul><li>命令模式下 回车Enter 或 鼠标双击 cell进入编辑模式</li><li>可以操作cell内文本或代码，剪切／复制／粘贴移动等操作</li></ul><p>命令模式（Esc）</p><ul><li>按 Esc 退出编辑，进入命令模式</li><li>可以操作cell单元本身进行剪切／复制／粘贴／移动等操作</li></ul><p>3.2.1 鼠标操作</p><p><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/%E9%BC%A0%E6%A0%87%E6%93%8D%E4%BD%9C.png"></p><p>3.2.2 快捷键操作</p><p>两种模式通用快捷键</p><ul><li><code>Shift+Enter</code> ，执行本单元代码，并跳转到下一单元</li><li><code>Ctrl+Enter</code> ，执行本单元代码，留在本单元</li></ul><p>命令模式：按ESC进入</p><ul><li>Y ，cell切换到Code模式</li><li>M ，cell切换到Markdown模式</li><li>A ，在当前cell的上面添加cell</li><li>B ，在当前cell的下面添加cell</li></ul><p>其他(了解)</p><ul><li>双击D ：删除当前cell</li><li>Z ，回退</li><li>L ，为当前cell加上行号</li><li><code>Ctrl+Shift+P</code> ，对话框输入命令直接运行</li><li>快速跳转到首个cell， <code>Crtl+Home</code></li><li>快速跳转到最后一个cell， <code>Crtl+End</code></li></ul><p>编辑模式：按Enter进入</p><ul><li>补全代码：变量、方法后跟 Tab键</li><li>为一行或多行代码添加/取消注释： <code>Ctrl+/</code> （Mac:CMD+/）</li></ul><p>其他(了解)：</p><ul><li>多光标操作： <code>Ctrl键点击鼠标</code> （Mac:CMD+点击鼠标）</li><li>回退： <code>Ctrl+Z</code> （Mac:CMD+Z）</li><li>重做： <code>Ctrl+Y</code> （Mac:CMD+Y)</li></ul><h4 id="3-3-markdown演示"><a href="#3-3-markdown演示" class="headerlink" title="3.3 markdown演示"></a>3.3 markdown演示</h4><p>掌握标题和缩进即可</p><h1 id="一级标题"><a href="#一级标题" class="headerlink" title="一级标题"></a>一级标题</h1><h2 id="二级标题"><a href="#二级标题" class="headerlink" title="二级标题"></a>二级标题</h2><h3 id="三级标题"><a href="#三级标题" class="headerlink" title="三级标题"></a>三级标题</h3><h4 id="四级标题"><a href="#四级标题" class="headerlink" title="四级标题"></a>四级标题</h4><h5 id="五级标题"><a href="#五级标题" class="headerlink" title="五级标题"></a>五级标题</h5><ul><li>缩进<ul><li>二级缩进<ul><li>三级缩进</li></ul></li></ul></li></ul><h3 id="Jupyter-Notebook中自动补全代码等相关功能拓展【了解】"><a href="#Jupyter-Notebook中自动补全代码等相关功能拓展【了解】" class="headerlink" title="Jupyter Notebook中自动补全代码等相关功能拓展【了解】"></a>Jupyter Notebook中自动补全代码等相关功能拓展【了解】</h3><h4 id="4-1-安装jupyter-contrib-nbextensions库"><a href="#4-1-安装jupyter-contrib-nbextensions库" class="headerlink" title="4.1 安装jupyter_contrib_nbextensions库"></a>4.1 安装jupyter_contrib_nbextensions库</h4><p>安装该库的命令如下：</p><blockquote><p>python -m pip install jupyter_contrib_nbextensions</p></blockquote><p>然后执行：</p><blockquote><p>jupyter contrib nbextension install –user –skip-running-check</p></blockquote><p>在原来的基础上勾选： “Table of Contents” 以及 “Hinterland”</p><p>部分功能：</p><p><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/jupyter%E5%AE%89%E8%A3%85%E5%BA%93.png"></p><h2 id="完整机器学习项目的流程（拓展阅读）"><a href="#完整机器学习项目的流程（拓展阅读）" class="headerlink" title="完整机器学习项目的流程（拓展阅读）"></a>完整机器学习项目的流程（拓展阅读）</h2><h3 id="1-抽象成数学问题"><a href="#1-抽象成数学问题" class="headerlink" title="1 抽象成数学问题"></a>1 抽象成数学问题</h3><p>明确问题是进行机器学习的第一步。机器学习的训练过程通常都是一件非常耗时的事情，胡乱尝试时间成本是非常高的。这里的抽象成数学问题，指的明确我们可以获得什么样的数据，抽象出的问题，是一个分类还是回归或者是聚类的问题。</p><h3 id="2-获取数据"><a href="#2-获取数据" class="headerlink" title="2 获取数据"></a>2 获取数据</h3><p>数据决定了机器学习结果的上限，而算法只是尽可能逼近这个上限。<br>数据要有代表性，否则必然会过拟合。<br>而且对于分类问题，数据偏斜不能过于严重，不同类别的数据数量不要有数量级的差距。<br>而且还要对数据的量级有一个评估，多少个样本，多少个特征，可以估算出其对内存的消耗程度，判断训练过程中内存是否能够放得下。如果放不下就得考虑改进算法或者使用一些降维的技巧了。如果数据量实在太大，那就要考虑分布式了。</p><h3 id="3-特征预处理与特征选择"><a href="#3-特征预处理与特征选择" class="headerlink" title="3 特征预处理与特征选择"></a>3 特征预处理与特征选择</h3><p>良好的数据要能够提取出良好的特征才能真正发挥作用。<br>特征预处理、数据清洗是很关键的步骤，往往能够使得算法的效果和性能得到显著提高。归一化、离散化、因子化、缺失值处理、去除共线性等，数据挖掘过程中很多时间就花在它们上面。这些工作简单可复制，收益稳定可预期，是机器学习的基础必备步骤。</p><p>筛选出显著特征、摒弃非显著特征，需要机器学习工程师反复理解业务。这对很多结果有决定性的影响。特征选择好了，非常简单的算法也能得出良好、稳定的结果。这需要运用特征有效性分析的相关技术，如相关系数、卡方检验、平均互信息、条件熵、后验概率、逻辑回归权重等方法。</p><h3 id="4-训练模型与调优"><a href="#4-训练模型与调优" class="headerlink" title="4 训练模型与调优"></a>4 训练模型与调优</h3><p>直到这一步才用到我们上面说的算法进行训练。现在很多算法都能够封装成黑盒供人使用。但是真正考验水平的是调整这些算法的（超）参数，使得结果变得更加优良。这需要我们对算法的原理有深入的理解。理解越深入，就越能发现问题的症结，提出良好的调优方案。</p><h3 id="5-模型诊断"><a href="#5-模型诊断" class="headerlink" title="5 模型诊断"></a>5 模型诊断</h3><p>如何确定模型调优的方向与思路呢？这就需要对模型进行诊断的技术。</p><p>过拟合、欠拟合 判断是模型诊断中至关重要的一步。常见的方法如交叉验证，绘制学习曲线等。过拟合的基本调优思路是增加数据量，降低模型复杂度。欠拟合的基本调优思路是提高特征数量和质量，增加模型复杂度。</p><p>误差分析 也是机器学习至关重要的步骤。通过观察误差样本全面分析产生误差的原因:是参数的问题还是算法选择的问题，是特征的问题还是数据本身的问题……</p><p>诊断后的模型需要进行调优，调优后的新模型需要重新进行诊断，这是一个反复迭代不断逼近的过程，需要不断地尝试， 进而达到最优状态。</p><h3 id="6-模型融合"><a href="#6-模型融合" class="headerlink" title="6 模型融合"></a>6 模型融合</h3><p>一般来说，模型融合后都能使得效果有一定提升。而且效果很好。<br>工程上，主要提升算法准确度的方法是分别在模型的前端（特征清洗和预处理，不同的采样模式）与后端（模型融合）上下功夫。因为他们比较标准可复制，效果比较稳定。而直接调参的工作不会很多，毕竟大量数据训练起来太慢了，而且效果难以保证。</p><h3 id="7-上线运行"><a href="#7-上线运行" class="headerlink" title="7 上线运行"></a>7 上线运行</h3><p>这一部分内容主要跟工程实现的相关性比较大。工程上是结果导向，模型在线上运行的效果直接决定模型的成败。 不单纯包括其准确程度、误差等情况，还包括其运行的速度(时间复杂度)、资源消耗程度（空间复杂度）、稳定性是否可接受。<br>这些工作流程主要是工程实践上总结出的一些经验。并不是每个项目都包含完整的一个流程。这里的部分只是一个指导性的说明，只有大家自己多实践，多积累项目经验，才会有自己更深刻的认识。</p><h2 id="独立同分布IID-independent-and-identically-distributed"><a href="#独立同分布IID-independent-and-identically-distributed" class="headerlink" title="独立同分布IID(independent and identically distributed)"></a>独立同分布IID(independent and identically distributed)</h2><h3 id="1-独立同分布-i-i-d"><a href="#1-独立同分布-i-i-d" class="headerlink" title="1.独立同分布(i.i.d.)"></a>1.独立同分布(i.i.d.)</h3><p>在概率统计理论中，如果变量序列或者其他随机变量有相同的概率分布，并且互相独立，那么这些随机变量是独立同分布。</p><p>在西瓜书中解释是：输入空间中的所有样本服从一个隐含未知的分布，训练数据所有样本都是独立地从这个分布上采样而得。</p><h3 id="2-简单解释-—-独立、同分布、独立同分布"><a href="#2-简单解释-—-独立、同分布、独立同分布" class="headerlink" title="2.简单解释 — 独立、同分布、独立同分布"></a>2.简单解释 — 独立、同分布、独立同分布</h3><p>（1）独立：每次抽样之间没有关系，不会相互影响<br>举例：给一个骰子，每次抛骰子抛到几就是几，这是独立；如果我要抛骰子两次之和大于8，那么第一次和第二次抛就不独立，因为第二次抛的结果和第一次相关。</p><p>（2）同分布：每次抽样，样本服从同一个分布<br>举例：给一个骰子，每次抛骰子得到任意点数的概率都是六分之一，这个就是同分布</p><p>（3）独立同分布：i.i.d.，每次抽样之间独立而且同分布</p><h3 id="3-机器学习领域的重要假设"><a href="#3-机器学习领域的重要假设" class="headerlink" title="3.机器学习领域的重要假设"></a>3.机器学习领域的重要假设</h3><p>IID独立同分布即假设训练数据和测试数据是满足相同分布的，它是通过训练数据获得的模型能够在测试集获得好的效果的一个基本保障。</p><h3 id="4-目前发展"><a href="#4-目前发展" class="headerlink" title="4.目前发展"></a>4.目前发展</h3><p>机器学习并不总要求独立同分布，在不少问题中要求样本数据采样自同一个分布是因为希望用训练数据集得到的模型可以合理的用于测试数据集，使用独立同分布假设能够解释得通。</p><p>目前一些机器学习内容已经不再囿于独立同分布假设下，一些问题会假设样本没有同分布。</p><h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><h3 id="回归问题概述"><a href="#回归问题概述" class="headerlink" title="回归问题概述"></a>回归问题概述</h3><p>来源:<a target="_blank" rel="noopener" href="https://blog.csdn.net/iqdutao/article/details/109402570?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522163774011816780255279611%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=163774011816780255279611&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-109402570.first_rank_v2_pc_rank_v29&amp;utm_term=%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B&amp;spm=1018.2226.3001.4187">线性回归模型详解</a><br>回归分析的主要算法包括：</p><p>1.线性回归(Linear Regression)<br>2.逻辑回归（Logistic regressions）<br>3.多项式回归(Polynomial Regression)<br>4.逐步回归(Step Regression)<br>5.岭回归(Ridge Regression)<br>6.套索回归(Lasso Regression)<br>7.弹性网回归(ElasticNet)</p><p>线性与非线性</p><ul><li>线性：两个变量之间的关系是一次函数关系的——图象<code>是直线</code>,叫做线性。<br><code>注意：线性是指广义的线性,也就是数据与数据之间的关系</code>。</li><li>非线性：两个变量之间的关系不是一次函数关系的——图象<code>不是直线</code>,叫做非线性。</li></ul><p>那到底什么时候可以使用线性回归呢？统计学家安斯库姆给出了四个数据集,被称为安斯库姆四重奏。</p><p><img src="/liaojie.github.io/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/liaojie1314/PicGo/images/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%921png.png"></p><p>从这四个数据集的分布可以看出,并不是所有的数据集都可以用一元线性回归来建模。现实世界中的问题往往更复杂,变量几乎不可能非常理想化地符合线性模型的要求。因此使用线性回归,需要遵守下面几个假设：</p><ul><li>线性回归是一个回归问题。</li><li>要预测的变量 y 与自变量 x 的关系是线性的（图2 是一个非线性）。</li><li>各项误差服从正太分布,均值为0,与 x 同方差（图4 误差不是正太分布）。</li><li>变量 x 的分布要有变异性。</li><li>多元线性回归中不同特征之间应该相互独立,避免线性相关。</li></ul><p>参考：<br><img src="/liaojie.github.io/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/liaojie1314/PicGo/images/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%922.png"></p><h5 id="回归问题与分类问题"><a href="#回归问题与分类问题" class="headerlink" title="回归问题与分类问题"></a>回归问题与分类问题</h5><p>与回归相对的是分类问题（classification）,分类问题要预测的变量y输出集合是有限的,预测值只能是有限集合内的一个。当要预测的变量y输出集合是无限且连续,我们称之为回归。比如,天气预报预测明天是否下雨,是一个二分类问题；预测明天的降雨量多少,就是一个回归问题。</p><h5 id="变量之间是线性关系"><a href="#变量之间是线性关系" class="headerlink" title="变量之间是线性关系"></a>变量之间是线性关系</h5><p>线性通常是指变量之间保持等比例的关系,从图形上来看,变量之间的形状为直线,斜率是常数。这是一个非常强的假设,数据点的分布呈现复杂的曲线,则不能使用线性回归来建模。可以看出,四重奏右上角的数据就不太适合用线性回归的方式进行建模。</p><h5 id="误差服从均值为零的正态分布"><a href="#误差服从均值为零的正态分布" class="headerlink" title="误差服从均值为零的正态分布"></a>误差服从均值为零的正态分布</h5><p>前面最小二乘法求解过程已经提到了误差的概念,误差可以表示为误差 = 实际值 - 预测值。</p><p>可以这样理解这个假设：线性回归允许预测值与真实值之间存在误差,随着数据量的增多,这些数据的误差平均值为0；从图形上来看,各个真实值可能在直线上方,也可能在直线下方,当数据足够多时,各个数据上上下下相互抵消。如果误差不服从均值为零的正太分布,那么很有可能是出现了一些异常值,数据的分布很可能是安斯库姆四重奏右下角的情况。</p><p>这也是一个非常强的假设,如果要使用线性回归模型,那么必须假设数据的误差均值为零的正太分布。</p><h5 id="变量-x-的分布要有变异性"><a href="#变量-x-的分布要有变异性" class="headerlink" title="变量 x 的分布要有变异性"></a>变量 x 的分布要有变异性</h5><p>线性回归对变量 x也有要求,要有一定变化,不能像安斯库姆四重奏右下角的数据那样,绝大多数数据都分布在一条竖线上。</p><h5 id="多元线性回归不同特征之间相互独立"><a href="#多元线性回归不同特征之间相互独立" class="headerlink" title="多元线性回归不同特征之间相互独立"></a>多元线性回归不同特征之间相互独立</h5><p>如果不同特征不是相互独立,那么可能导致特征间产生共线性,进而导致模型不准确。举一个比较极端的例子,预测房价时使用多个特征：房间数量,房间数量x2,-房间数量等,特征之间是线性相关的,如果模型只有这些特征,缺少其他有效特征,虽然可以训练出一个模型,但是模型不准确,预测性差。<br>线性回归<br><img src="/liaojie.github.io/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/liaojie1314/PicGo/images/%E7%BA%BF%E6%80%A73.jpg"><br><img src="/liaojie.github.io/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/liaojie1314/PicGo/images/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%924.jpg"><br><img src="/liaojie.github.io/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/liaojie1314/PicGo/images/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%925.jpg"><br><img src="/liaojie.github.io/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/liaojie1314/PicGo/images/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%926.jpg"><br><img src="/liaojie.github.io/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/liaojie1314/PicGo/images/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%927.jpg"><br><img src="/liaojie.github.io/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/liaojie1314/PicGo/images/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%928.jpg"><br><img src="/liaojie.github.io/medias/loading.gif" data-original="https://cdn.jsdelivr.net/gh/liaojie1314/PicGo/images/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%929.jpg"></p><h3 id="多重共线性"><a href="#多重共线性" class="headerlink" title="多重共线性"></a>多重共线性</h3><p>在多元线性回归模型经典假设中,其重要假定之一是回归模型的解释变量之间不存在线性关系,也就是说,解释变量X1,X2,……,Xk中的任何一个都不能是其他解释变量的线性组合。如果违背这一假定,即线性回归模型中某一个解释变量与其他解释变量间存在线性关系,就称线性回归模型中存在多重共线性。严重的多重共线性可能会产生问题,因为它可以增大回归系数的方差,使它们变得不稳定。以下是不稳定系数导致的一些后果：</p><ul><li>即使预测变量和响应之间存在显著关系,系数也可能看起来并不显著。</li><li>高度相关的预测变量的系数在样本之间差异很大。</li><li>从模型中去除任何高度相关的项都将大幅影响其他高度相关项的估计系数。高度相关项的系数甚至会包含错误的符号。</li></ul><h5 id="共线性出现的原因"><a href="#共线性出现的原因" class="headerlink" title="共线性出现的原因"></a>共线性出现的原因</h5><p>多重共线性问题就是指一个解释变量的变化引起另一个解释变量地变化。</p><p>原本自变量应该是各自独立的,根据回归分析结果,能得知哪些因素对因变量Y有显著影响,哪些没有影响。如果各个自变量x之间有很强的线性关系,就无法固定其他变量,也就找不到x和y之间真实的关系了。除此以外,多重共线性的原因还可能包括：</p><ul><li>数据不足。在某些情况下,收集更多数据可以解决共线性问题。</li><li>错误地使用虚拟变量。（比如,同时将男、女两个虚拟变量都放入模型,此时必定出现共线性,称为完全共线性）</li></ul><h5 id="共线性的判别指标"><a href="#共线性的判别指标" class="headerlink" title="共线性的判别指标"></a>共线性的判别指标</h5><p>有多种方法可以检测多重共线性,较常使用的是回归分析中的VIF值,VIF值越大,多重共线性越严重。一般认为VIF大于10时（严格是5）,代表模型存在严重的共线性问题。有时候也会以容差值作为标准,容差值=1/VIF,所以容差值大于0.1则说明没有共线性(严格是大于0.2),VIF和容差值有逻辑对应关系,两个指标任选其一即可。</p><p>除此之外,直接对自变量进行相关分析,查看相关系数和显著性也是一种判断方法。如果一个自变量和其他自变量之间的相关系数显著,则代表可能存在多重共线性问题。</p><p>如存在严重的多重共线性问题,可以考虑使用以下几种方法处理：</p><h5 id="（1）手动移除出共线性的变量"><a href="#（1）手动移除出共线性的变量" class="headerlink" title="（1）手动移除出共线性的变量"></a>（1）手动移除出共线性的变量</h5><p>先做下相关分析,如果发现某两个自变量X（解释变量）的相关系数值大于0.7,则移除掉一个自变量（解释变量）,然后再做回归分析。此方法是最直接的方法,但有的时候我们不希望把某个自变量从模型中剔除,这样就要考虑使用其他方法。</p><h5 id="（2）逐步回归法"><a href="#（2）逐步回归法" class="headerlink" title="（2）逐步回归法"></a>（2）逐步回归法</h5><p>让系统自动进行自变量的选择剔除,使用逐步回归将共线性的自变量自动剔除出去。此种解决办法有个问题是,可能算法会剔除掉本不想剔除的自变量,如果有此类情况产生,此时最好是使用岭回归进行分析。</p><h5 id="（3）增加样本容量"><a href="#（3）增加样本容量" class="headerlink" title="（3）增加样本容量"></a>（3）增加样本容量</h5><p>增加样本容量是解释共线性问题的一种办法,但在实际操作中可能并不太适合,原因是样本量的收集需要成本时间等。</p><h5 id="（4）岭回归"><a href="#（4）岭回归" class="headerlink" title="（4）岭回归"></a>（4）岭回归</h5><p>上述第1和第2种解决办法在实际研究中使用较多,但问题在于,如果实际研究中并不想剔除掉某些自变量,某些自变量很重要,不能剔除。此时可能只有岭回归最为适合了。岭回归是当前解决共线性问题最有效的解释办法。</p><h3 id="常用的回归模型评估指标"><a href="#常用的回归模型评估指标" class="headerlink" title="常用的回归模型评估指标"></a>常用的回归模型评估指标</h3><ul><li>解释方差（ Explained variance score）</li><li>绝对平均误差（Mean absolute error）</li><li>均方误差（Mean squared error）</li><li>决定系数（R² score）</li></ul><h3 id="算法优缺点"><a href="#算法优缺点" class="headerlink" title="算法优缺点"></a>算法优缺点</h3><p>　　优点：</p><p>　　　　（1）思想简单,实现容易。建模迅速,对于小数据量、简单的关系很有效；</p><p>　　　　（2）是许多强大的非线性模型的基础。</p><p>　　　　（3）线性回归模型十分容易理解,结果具有很好的可解释性,有利于决策分析。</p><p>　　　　（4）蕴含机器学习中的很多重要思想。</p><p>　　　　（5）能解决回归问题。</p><p>　　缺点：</p><p>　　　　（1）对于非线性数据或者数据特征间具有相关性多项式回归难以建模.</p><p>　　　　（2）难以很好地表达高度复杂的数据。</p><h3 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h3><h5 id="简单的线性回归算法"><a href="#简单的线性回归算法" class="headerlink" title="简单的线性回归算法"></a>简单的线性回归算法</h5><pre class="line-numbers language-Python" data-language="Python"><code class="language-Python">import numpy as np
import matplotlib.pyplot as plt
 
x=np.array([1,2,3,4,5],dtype=np.float)
y=np.array([1,3.0,2,3,5])
plt.scatter(x,y)
 
x_mean=np.mean(x)
y_mean=np.mean(y)
num=0.0
d=0.0
for x_i,y_i in zip(x,y):
    num+=(x_i-x_mean)*(y_i-y_mean)
    d+=(x_i-x_mean)**2
    a=num/d
    b=y_mean-a*x_mean
y_hat=a*x+b
 
plt.figure(2)
plt.scatter(x,y)
plt.plot(x,y_hat,c='r')
x_predict=4.8
y_predict=a*x_predict+b
print(y_predict)
plt.scatter(x_predict,y_predict,c='b',marker='+')<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h5 id="基于sklearn的简单线性回归"><a href="#基于sklearn的简单线性回归" class="headerlink" title="基于sklearn的简单线性回归"></a>基于sklearn的简单线性回归</h5><pre class="line-numbers language-Python" data-language="Python"><code class="language-Python">import numpy as np 
import matplotlib.pyplot as plt  
from sklearn.linear_model import LinearRegression  # 线性回归
 
 
# 样本数据集,第一列为x,第二列为y,在x和y之间建立回归模型
data=[
    [0.067732,3.176513],[0.427810,3.816464],[0.995731,4.550095],[0.738336,4.256571],[0.981083,4.560815],
    [0.526171,3.929515],[0.378887,3.526170],[0.033859,3.156393],[0.132791,3.110301],[0.138306,3.149813],
    [0.247809,3.476346],[0.648270,4.119688],[0.731209,4.282233],[0.236833,3.486582],[0.969788,4.655492],
    [0.607492,3.965162],[0.358622,3.514900],[0.147846,3.125947],[0.637820,4.094115],[0.230372,3.476039],
    [0.070237,3.210610],[0.067154,3.190612],[0.925577,4.631504],[0.717733,4.295890],[0.015371,3.085028],
    [0.335070,3.448080],[0.040486,3.167440],[0.212575,3.364266],[0.617218,3.993482],[0.541196,3.891471]
]
 
 
#生成X和y矩阵
dataMat = np.array(data)
X = dataMat[:,0:1]   # 变量x
y = dataMat[:,1]   #变量y
 
 
# ========线性回归========
model = LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)
model.fit(X, y)   # 线性回归建模
print('系数矩阵:\n',model.coef_)
print('线性回归模型:\n',model)
# 使用模型预测
predicted = model.predict(X)
 
plt.scatter(X, y, marker='x')
plt.plot(X, predicted,c='r')
 
plt.xlabel("x")
plt.ylabel("y")<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>系数矩阵:<br>[ 1.6314263]<br>线性回归模型:<br>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)</p></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/liaojie.github.io/about" rel="external nofollow noreferrer">liaojie</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://liaojie.github.io.git/liaojie.github.io/2021/11/14/machinelearning/">https://liaojie.github.io.git/liaojie.github.io/2021/11/14/machinelearning/</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/liaojie.github.io/about" target="_blank">liaojie</a> !</span></div></div><script async defer>document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/liaojie.github.io/tags/Python/"><span class="chip bg-color">Python</span> </a><a href="/liaojie.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="chip bg-color">机器学习</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="/liaojie.github.io/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="/liaojie.github.io/libs/share/js/social-share.min.js"></script></div></div></div><style>#reward{margin:40px 0;text-align:center}#reward .reward-link{font-size:1.4rem;line-height:38px}#reward .btn-floating:hover{box-shadow:0 6px 12px rgba(0,0,0,.2),0 5px 15px rgba(0,0,0,.2)}#rewardModal{width:320px;height:350px}#rewardModal .reward-title{margin:15px auto;padding-bottom:5px}#rewardModal .modal-content{padding:10px}#rewardModal .close{position:absolute;right:15px;top:15px;color:rgba(0,0,0,.5);font-size:1.3rem;line-height:20px;cursor:pointer}#rewardModal .close:hover{color:#ef5350;transform:scale(1.3);-moz-transform:scale(1.3);-webkit-transform:scale(1.3);-o-transform:scale(1.3)}#rewardModal .reward-tabs{margin:0 auto;width:210px}.reward-tabs .tabs{height:38px;margin:10px auto;padding-left:0}.reward-content ul{padding-left:0!important}.reward-tabs .tabs .tab{height:38px;line-height:38px}.reward-tabs .tab a{color:#fff;background-color:#ccc}.reward-tabs .tab a:hover{background-color:#ccc;color:#fff}.reward-tabs .wechat-tab .active{color:#fff!important;background-color:#22ab38!important}.reward-tabs .alipay-tab .active{color:#fff!important;background-color:#019fe8!important}.reward-tabs .reward-img{width:210px;height:210px}</style><div id="reward"><a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a><div id="rewardModal" class="modal"><div class="modal-content"><a class="close modal-close"><i class="fas fa-times"></i></a><h4 class="reward-title">你的赏识是我前进的动力</h4><div class="reward-content"><div class="reward-tabs"><ul class="tabs row"><li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li><li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li></ul><div id="alipay"><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码"></div><div id="wechat"><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码"></div></div></div></div></div></div><script>$(function(){$(".tabs").tabs()})</script></div></div><link rel="stylesheet" href="/liaojie.github.io/libs/gitalk/gitalk.css"><link rel="stylesheet" href="/liaojie.github.io/css/my-gitalk.css"><div class="card gitalk-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="gitalk-container" class="card-content"></div></div><script src="/liaojie.github.io/libs/gitalk/gitalk.min.js"></script><script>let gitalk = new Gitalk({
        clientID: 'eedac85cd6c0645124b2',
        clientSecret: '0cbb1e584813da4a45008d2c6048fc84846ef93f',
        repo: 'liaojie1314-gitalk',
        owner: 'liaojie1314',
        admin: "liaojie1314",
        id: '2021-11-14T17-36-12',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');</script><div class="livere-card card" data-aos="fade-up"><div id="lv-container" class="card-content" data-id="city" data-uid="MTAyMC81NDUzMy8zMTAwNA=="><script type="text/javascript">(function (d, s) {
                let j, e = d.getElementsByTagName(s)[0];
                if (typeof LivereTower === 'function') {
                    return;
                }

                j = d.createElement(s);
                j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
                j.async = true;

                e.parentNode.insertBefore(j, e);
            })(document, 'script');</script><noscript>为正常使用来必力评论功能请激活JavaScript。</noscript></div></div><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/liaojie.github.io/2021/11/14/launchmode/"><div class="card-image"><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/featureimages/14.jpg" class="responsive-img" alt="launchMode"> <span class="card-title">launchMode</span></div></a><div class="card-content article-content"><div class="summary block-with-text"></div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2021-11-14 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/liaojie.github.io/categories/Android/" class="post-category">Android</a></span></div></div><div class="card-action article-tags"><a href="/liaojie.github.io/tags/Android/"><span class="chip bg-color">Android</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/liaojie.github.io/2021/11/12/springcloud/"><div class="card-image"><img src="/liaojie.github.io/medias/loading.gif" data-original="/liaojie.github.io/medias/featureimages/9.jpg" class="responsive-img" alt="Java学习之SpringCloud"> <span class="card-title">Java学习之SpringCloud</span></div></a><div class="card-content article-content"><div class="summary block-with-text"></div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2021-11-12 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/liaojie.github.io/categories/Java/" class="post-category">Java</a></span></div></div><div class="card-action article-tags"><a href="/liaojie.github.io/tags/Java/"><span class="chip bg-color">Java</span></a></div></div></div></div></article></div><script type="text/javascript" src="/liaojie.github.io/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="/liaojie.github.io/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="/liaojie.github.io/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="/liaojie.github.io/libs/codeBlock/codeShrink.js"></script></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget card" style="background-color:#fff"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="/liaojie.github.io/libs/tocbot/tocbot.min.js"></script><script>$(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });</script></main><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:15px!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2021-2022</span> <span id="year">2021</span> <a href="/liaojie.github.io/about" target="_blank">lj</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">287.9k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><span id="sitetime">载入运行时间...</span><script>function siteTime(){var e=36e5,t=24*e,n=new Date,o="2021",r=n.getFullYear(),a=n.getMonth()+1,i=n.getDate(),l=n.getHours(),m=n.getMinutes(),M=n.getSeconds(),g=Date.UTC(o,"10","18","0","0","0"),d=Date.UTC(r,a,i,l,m,M)-g,s=Math.floor(d/31536e6),u=Math.floor(d/t-365*s),T=Math.floor((d-(365*s+u)*t)/e),c=Math.floor((d-(365*s+u)*t-T*e)/6e4),f=Math.floor((d-(365*s+u)*t-T*e-6e4*c)/1e3);o==r?(document.getElementById("year").innerHTML=r,document.getElementById("sitetime").innerHTML="本站已安全运行 "+u+" 天 "+T+" 小时 "+c+" 分钟 "+f+" 秒"):(document.getElementById("year").innerHTML=o+" - "+r,document.getElementById("sitetime").innerHTML="本站已安全运行 "+s+" 年 "+u+" 天 "+T+" 小时 "+c+" 分钟 "+f+" 秒")}setInterval(siteTime,1e3)</script><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/liaojie1314" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:1517438366@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1517438366" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1517438366" data-position="top" data-delay="50"><i class="fab fa-qq"></i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script type="text/javascript">$(function(){!function(t,i,s){"use strict";$.ajax({url:t,dataType:"xml",success:function(t){var e=$("entry",t).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get(),n=document.getElementById(i),r=document.getElementById(s);n.addEventListener("input",function(){var f='<ul class="search-result-list">',m=this.value.trim().toLowerCase().split(/[\s\-]+/);r.innerHTML="",this.value.trim().length<=0||(e.forEach(function(t){var n,e,r,i,s,l=!0,a=t.title.trim().toLowerCase(),c=t.content.trim().replace(/<[^>]+>/g,"").toLowerCase(),u=0===(u=t.url).indexOf("/")?t.url:"/"+u,o=-1,h=-1;""!==a&&""!==c&&m.forEach(function(t,e){n=a.indexOf(t),o=c.indexOf(t),n<0&&o<0?l=!1:(o<0&&(o=0),0===e&&(h=o))}),l&&(f+="<li><a href='"+u+"' class='search-result-title'>"+a+"</a>",e=t.content.trim().replace(/<[^>]+>/g,""),0<=h&&(i=h+80,(r=h-20)<0&&(r=0),0===r&&(i=100),i>e.length&&(i=e.length),s=e.substr(r,i),m.forEach(function(t){var e=new RegExp(t,"gi");s=s.replace(e,'<em class="search-keyword">'+t+"</em>")}),f+='<p class="search-result">'+s+"...</p>"),f+="</li>")}),f+="</ul>",r.innerHTML=f)})}})}("/liaojie.github.io/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-arrow-up"></i></a></div><script src="/liaojie.github.io/libs/materialize/materialize.min.js"></script><script src="/liaojie.github.io/libs/masonry/masonry.pkgd.min.js"></script><script src="/liaojie.github.io/libs/aos/aos.js"></script><script src="/liaojie.github.io/libs/scrollprogress/scrollProgress.min.js"></script><script src="/liaojie.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="/liaojie.github.io/js/matery.js"></script><script type="text/javascript" color="122 103 238" opacity="0.7" zindex="-2" count="200" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script><script type="text/javascript">var st,OriginTitile=document.title;document.addEventListener("visibilitychange",function(){document.hidden?(document.title="ヽ(●-`Д´-)ノ你要玩捉迷藏嘛",clearTimeout(st)):(document.title="(Ő∀Ő3)ノ好哦！",st=setTimeout(function(){document.title=OriginTitile},3e3))})</script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script src="/liaojie.github.io/libs/others/clicklove.js" async></script><script async src="/liaojie.github.io/libs/others/busuanzi.pure.mini.js"></script><script src="/liaojie.github.io/libs/instantpage/instantpage.js" type="module"></script><script>window.imageLazyLoadSetting={isSPA:!1,preloadRatio:1,processImages:null}</script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})})</script><script>!function(n){n.imageLazyLoadSetting.processImages=o;var e=n.imageLazyLoadSetting.isSPA,i=n.imageLazyLoadSetting.preloadRatio||1,r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function o(){e&&(r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")));for(var t,a=0;a<r.length;a++)0<=(t=(t=r[a]).getBoundingClientRect()).bottom&&0<=t.left&&t.top<=(n.innerHeight*i||document.documentElement.clientHeight*i)&&function(){var e=r[a],t=e,n=function(){r=r.filter(function(t){return e!==t})},i=new Image,o=t.getAttribute("data-original");i.onload=function(){t.src=o,n()},t.src!==o&&(i.src=o)}()}o(),n.addEventListener("scroll",function(){var t=o,e=n;clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(e)},500)})}(this)</script></body></html>